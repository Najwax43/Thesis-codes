{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Change tensorflow version from 2.6.4 to 2.9.1\n\nI noticed that the default version of tensorflow (2.6.4) has a problem of printing unecessary clean up messages. for this reason I upgraded to tensorflow 2.9.1","metadata":{"_uuid":"5abe902d-0cd4-4632-9929-728cbad124e8","_cell_guid":"d31816e1-46f6-40fc-a1f8-410d478a53ba","trusted":true}},{"cell_type":"code","source":"!pip uninstall tensorflow --yes\n!pip install tensorflow_decision_forests\n!apt install --allow-change-held-packages libcudnn8=8.1.0.77-1+cuda11.2 --yes\n!pip install kerassurgeon","metadata":{"_uuid":"166039cd-9f53-4bee-a0b7-3e909088c359","_cell_guid":"90375ae9-73e9-4abe-a1ac-c1eb1d2a5ef8","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-11-07T06:19:26.687878Z","iopub.execute_input":"2022-11-07T06:19:26.688309Z","iopub.status.idle":"2022-11-07T06:21:50.414594Z","shell.execute_reply.started":"2022-11-07T06:19:26.688226Z","shell.execute_reply":"2022-11-07T06:21:50.413404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Library\nhere are the required packages/modules we will use to perform the tasks","metadata":{"_uuid":"15d9d56d-f23b-4a0b-a7c4-2baed0b47754","_cell_guid":"b65d76c0-8735-4953-9a4d-b5ef601ea493","trusted":true}},{"cell_type":"code","source":"import os\nimport cv2\nimport gc\nimport numpy as np\nimport pandas as pd\nimport glob\nimport pathlib\nimport tensorflow as tf\nimport tensorflow_addons as tfa\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport keras\nfrom keras.preprocessing.image import ImageDataGenerator\n#from keras.preprocessing.image import img_to_array, load_img\nfrom tensorflow.keras import datasets, layers, models,Input,Model \nimport tensorflow_datasets as tfds\nfrom keras.models import Sequential\nfrom keras.layers import  Bidirectional, Conv2D, BatchNormalization, MaxPooling2D, Flatten, LSTM, Dense, Lambda, Dropout,Reshape\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import metrics\nfrom tensorflow.keras.metrics import Accuracy, Recall,Precision\nfrom sklearn.tree import DecisionTreeClassifier as Decisiontree\nfrom sklearn.svm import SVC as Supportvectorclassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV\nimport time\nfrom functools import reduce\nfrom kerassurgeon.operations import delete_layer, insert_layer\nfrom keras.utils import to_categorical\nimport pickle","metadata":{"_uuid":"9867451e-6aee-4165-8fd6-cbdf068425e1","_cell_guid":"6f86da36-f689-48d5-a1b8-b977eacf78ea","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-11-07T06:34:41.307559Z","iopub.execute_input":"2022-11-07T06:34:41.307941Z","iopub.status.idle":"2022-11-07T06:34:41.317322Z","shell.execute_reply.started":"2022-11-07T06:34:41.307908Z","shell.execute_reply":"2022-11-07T06:34:41.316368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Just checking if tensorflow was sucessfully upgraded.","metadata":{"_uuid":"93d060a1-7efe-4ca9-939f-e4c90896bc31","_cell_guid":"3156c957-2178-400c-9574-f4597ef179e4","trusted":true}},{"cell_type":"code","source":"print(tf.__version__)","metadata":{"_uuid":"7370090f-e717-418e-a01c-a5cccdaa0112","_cell_guid":"98bd7d11-634d-45b8-a752-8e0f7784488a","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-11-07T06:21:56.005178Z","iopub.execute_input":"2022-11-07T06:21:56.007486Z","iopub.status.idle":"2022-11-07T06:21:56.015764Z","shell.execute_reply.started":"2022-11-07T06:21:56.007409Z","shell.execute_reply":"2022-11-07T06:21:56.012974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Introduction\nThis study utilized a secondary radiography dataset, retrieved from the Kaggle data repository. The original copy was compiled from publicly available posterior-to-anterior (AP) chest x-rays by a group of research collaborators from Qatar and Bangladesh. The experimental setting involved a placebo type of design with 3 study groups; these include A control group with 423 x-ray images from normal people, an experimental group with 1579 x-ray images from COVID infected persons, and a group with viral pneumonia infected persons with 1485 images (Chowdhury et al., 2020). The data will be split into a training set with 75% and a testing set with 25%, during the preprocessing step. The testing set will be held to help evaluate the performance of the models on new data.","metadata":{"_uuid":"17a1a9ce-2b4f-46b1-b242-e1d2c5c5e3df","_cell_guid":"cacddadd-1435-4998-98b2-cbd2f1dd912b","trusted":true}},{"cell_type":"markdown","source":"# Loading the data\n\nHere I will load the image data.I will use the tensorlow `image_from_directory()`  which I consider efficient in loading image data.  Images will be loaded in their original form of `299x 299` shape.\n\nWe have a total of **13808** images in consideration, **10192** are from normal cases while **3616** are from covid infected cases. The overall data was randomly split into **80%(11047)** training images and **20%(2761)** testing images.\n\nAbout **8163** of the training images are from normal people while the rest are from covid patients. For testing **2029** are from normal people while the rest are covid infected cases. \n\nThe data is saved as  batched tensorflow images with batch sizes of 32 images.There is a total of 346 batches on the training set and 87 images on the training.\n\nData link:https://www.kaggle.com/najwa2030/the-original-model/edit","metadata":{"_uuid":"907bc0ed-b965-4300-bc76-d7874a881f92","_cell_guid":"4cca51f6-c00d-4756-b9e9-691d8e5f2986","trusted":true}},{"cell_type":"code","source":"# some parameter settings\n\nbatch_size=32\nimage_height=299\nimage_width=299\nn=1000\nepochs=100","metadata":{"_uuid":"f7816e26-ec2c-4fdb-af11-b50167d407ff","_cell_guid":"6737e6d5-87e2-41a7-95dc-90036e28e6f1","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-11-07T06:21:56.027469Z","iopub.execute_input":"2022-11-07T06:21:56.032822Z","iopub.status.idle":"2022-11-07T06:21:56.037804Z","shell.execute_reply.started":"2022-11-07T06:21:56.032786Z","shell.execute_reply":"2022-11-07T06:21:56.036728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"here we are loading the images from the folder they are saved.Tensorflow pipeline will be used to allow flow of images from directory.","metadata":{"_uuid":"0a988552-7873-47cf-8ed7-29c1680c89e5","_cell_guid":"70bf9f53-24dc-4562-b17e-d053e15534c2","trusted":true}},{"cell_type":"code","source":"# reading images from directory(folder)\n\ndata_dir= \"../input/mycoviddata/covid images/binary\"\ntrain_ds= tf.keras.utils.image_dataset_from_directory(\n  data_dir,\n  color_mode='grayscale',\n  labels='inferred',\n  label_mode='categorical',\n  subset=\"training\",\n  image_size=(image_height,image_width),\n  validation_split=0.20,\n  seed=100)\n\ntest_ds= tf.keras.utils.image_dataset_from_directory(\n  data_dir,\n  color_mode='grayscale',\n  labels='inferred',\n  label_mode='categorical',\n  subset=\"validation\",\n  image_size=(299, 299),\n  validation_split=0.20,\n  seed=100)","metadata":{"_uuid":"86d6c029-f581-4c5f-96b1-1e54a2b3f4ee","_cell_guid":"40d93ed4-33cc-4f54-881f-03bf07262126","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-11-07T06:21:56.039581Z","iopub.execute_input":"2022-11-07T06:21:56.040363Z","iopub.status.idle":"2022-11-07T06:22:25.370234Z","shell.execute_reply.started":"2022-11-07T06:21:56.040319Z","shell.execute_reply":"2022-11-07T06:22:25.369200Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Your images belong to these two directories. COVID and Normal","metadata":{"_uuid":"54a615ee-2418-4b00-a344-8c9fe4b15d87","_cell_guid":"bde2d2a0-e382-4e3a-9fe1-85ac827654d0","trusted":true}},{"cell_type":"code","source":"# Class names\ntrain_ds.class_names","metadata":{"_uuid":"6d7af73b-416d-4899-b56c-503d9ed6c541","_cell_guid":"9b46d0a5-8d57-4e13-8aa6-a124a64eda64","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-11-07T06:22:25.372477Z","iopub.execute_input":"2022-11-07T06:22:25.373165Z","iopub.status.idle":"2022-11-07T06:22:25.381769Z","shell.execute_reply.started":"2022-11-07T06:22:25.373125Z","shell.execute_reply":"2022-11-07T06:22:25.380593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here we collected details of the image, such as image counts in each group, training size and testing size etc. they are the details graphed below.","metadata":{"_uuid":"d16a726c-ca3f-4924-a046-fd0555f01231","_cell_guid":"c28ee767-7ff2-48d2-9dae-4f6a3d0b295a","trusted":true}},{"cell_type":"code","source":"# preparing summary counts\ndata_dir=pathlib.Path('../input/mycoviddata/covid images/binary')\n\n# function to get labs \ndef fetch_labels(filepath):\n    return str(filepath).split('/')[-2]\n\n# Training labels\nlabs=list(map(fetch_labels,train_ds.file_paths))\ntrainlabs=pd.DataFrame(labs,columns=[\"Labels\"])\n\n# testing labels\nlabs=list(map(fetch_labels,test_ds.file_paths))\ntestlabs=pd.DataFrame(labs,columns=[\"Labels\"])\n\n# Overall image count\ndf=pd.DataFrame([[\"Normal\",len(list(data_dir.glob('Normal/*.png')))],\n              [\"COVID\",len(list(data_dir.glob('COVID/*.png')))]]\n             , columns=['Label','count'])\n# batch count\ndf1=pd.DataFrame([[\"Training\",len(train_ds)],\n              [\"Testing\",len(test_ds)]]\n             , columns=['Label','count'])","metadata":{"_uuid":"9371a1fb-53cd-495f-988e-982f7175648b","_cell_guid":"c0107e13-0227-453c-a318-d1f9d0d27bd7","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-11-07T06:22:25.383399Z","iopub.execute_input":"2022-11-07T06:22:25.384017Z","iopub.status.idle":"2022-11-07T06:22:25.465234Z","shell.execute_reply.started":"2022-11-07T06:22:25.383982Z","shell.execute_reply":"2022-11-07T06:22:25.464306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"-------------- Overall data ------------------------------------\\n\")\nprint(\"image count:\",len(list(data_dir.glob('*/*.png'))))\nprint(\"Normal image count:\",len(list(data_dir.glob('Normal/*.png'))))\nprint(\"Covid image count:\",len(list(data_dir.glob('COVID/*.png'))))\n\nprint(\"\\n------------Train test split--------------------------------\\n\")\nprint(\"Training count:\",len(trainlabs))\nprint(\"Testing count:\",len(testlabs))\nprint(\"Number of batches training set:\",len(train_ds))\nprint(\"Number of batches testing set:\",len(test_ds))","metadata":{"_uuid":"67d4ffc2-cc1e-4699-804e-75f3ae29914b","_cell_guid":"e31f67aa-f3fd-4a4c-a6cd-5f86a397ed15","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-11-07T06:22:25.466720Z","iopub.execute_input":"2022-11-07T06:22:25.467058Z","iopub.status.idle":"2022-11-07T06:22:25.567600Z","shell.execute_reply.started":"2022-11-07T06:22:25.467019Z","shell.execute_reply":"2022-11-07T06:22:25.566549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"figure,ax=plt.subplots(nrows=2,ncols=2,figsize=(12,10))\nsns.barplot(x = 'Label',y = 'count',data = df,ax=ax[0,0])\nsns.countplot(x='Labels',data=trainlabs,ax=ax[0,1])\nsns.countplot(x='Labels',data=testlabs,ax=ax[1,0])\nsns.barplot(x = 'Label',y = 'count',data = df1,ax=ax[1,1])\nax[0,0].set_title('Total Images')\nax[0,1].set_title('Training images')\nax[1,0].set_title('Testing images')\nax[1,1].set_title('Batch counts')\nfor p, label in zip(ax[0,1].patches, trainlabs['Labels'].value_counts().index):\n    ax[0,1].annotate(p.get_height(), (p.get_x()+0.25, p.get_height()+20))\nfor p, label in zip(ax[1,0].patches, testlabs['Labels'].value_counts().index):\n    ax[1,0].annotate(p.get_height(), (p.get_x()+0.25, p.get_height()+20))\nfor p, label in zip(ax[0,0].patches, df['count'].index):\n    ax[0,0].annotate(round(p.get_height()), (p.get_x()+0.25, p.get_height()+20))\nfor p, label in zip(ax[1,1].patches, df1['count'].index):\n    ax[1,1].annotate(round(p.get_height()), (p.get_x()+0.25, p.get_height()+5))\nax[0,0].set_xlabel(\"\")\nax[0,1].set_xlabel(\"\")\nax[1,0].set_xlabel(\"\")\nax[1,1].set_xlabel(\"\")\n    \nplt.savefig('original data1.png')","metadata":{"_uuid":"ca7081bc-a65c-467b-9d36-db3ae7b6d175","_cell_guid":"6598daf4-4686-4d03-a210-0b14b7097194","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-11-07T06:22:25.569052Z","iopub.execute_input":"2022-11-07T06:22:25.569380Z","iopub.status.idle":"2022-11-07T06:22:26.212810Z","shell.execute_reply.started":"2022-11-07T06:22:25.569346Z","shell.execute_reply":"2022-11-07T06:22:26.211901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualizing a sample of the images\n\nBelow I visualized a sample of 16 images,to see if the labels are matched properly.","metadata":{"_uuid":"c31ff797-50f6-4c9c-a7a9-69fab5216a7a","_cell_guid":"001de46d-82cd-4a6e-a719-4ad9fc13b203","trusted":true}},{"cell_type":"code","source":"plt.figure(figsize=(10, 10))\nfor images, labels in train_ds.take(1):\n    for i in range(16):\n        ls=labels[i].numpy()\n        x=[j for j, y in enumerate(ls) if y == 1]\n        ax = plt.subplot(4, 4, i + 1)\n        plt.imshow(images[i].numpy().astype(\"uint8\"),cmap='Greys_r')\n        plt.title(train_ds.class_names[x[0]])\n        plt.axis(\"off\")\n        \nplt.savefig('original data2.png')","metadata":{"_uuid":"e9cf221e-a34a-4b58-9e65-e5c4d3d82d69","_cell_guid":"66a216b7-297e-4710-9092-e3551589d4f4","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-11-07T06:22:26.216266Z","iopub.execute_input":"2022-11-07T06:22:26.216578Z","iopub.status.idle":"2022-11-07T06:22:28.551031Z","shell.execute_reply.started":"2022-11-07T06:22:26.216550Z","shell.execute_reply":"2022-11-07T06:22:28.547401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here are tensorflow commands to allow prefetching and caching. This has to do with tensorflow, when using tensorflow caching means, the data will cached after first epoch. so will not be loaded afresh everytime. prefetching means processing is overlapped(sort of multi-tasking)","metadata":{"_uuid":"4d4e7820-3347-4315-b8c1-a8889a3f32e6","_cell_guid":"86783f4a-32f8-4563-acad-ffac0614522f","trusted":true}},{"cell_type":"code","source":"# performance configuration\nAUTOTUNE = tf.data.AUTOTUNE\ntrain_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\ntest_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)","metadata":{"_uuid":"fddbf657-2c8b-4eeb-91cd-8ca3797eb722","_cell_guid":"2cdecf10-e965-4d7b-8976-35a06bbeff3a","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-11-07T06:22:28.552019Z","iopub.execute_input":"2022-11-07T06:22:28.552333Z","iopub.status.idle":"2022-11-07T06:22:28.569588Z","shell.execute_reply.started":"2022-11-07T06:22:28.552303Z","shell.execute_reply":"2022-11-07T06:22:28.568708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def benchmark(dataset):\n    num_epochs\n    start_time = time.perf_counter()\n    for epoch_num in range(num_epochs):\n        for sample in dataset:\n            # Performing a training step\n            time.sleep(0.01)\n    print(\"Execution time:\", time.perf_counter() - start_time)","metadata":{"execution":{"iopub.status.busy":"2022-11-07T06:22:28.570937Z","iopub.execute_input":"2022-11-07T06:22:28.571375Z","iopub.status.idle":"2022-11-07T06:22:28.598009Z","shell.execute_reply.started":"2022-11-07T06:22:28.571341Z","shell.execute_reply":"2022-11-07T06:22:28.597049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n# Modelling \n\n Over the recent past, Convolution Neural Networks (CNN or Convnet) has gained popularity in visual imagery and video processing (Wu et al., 2017). This is due to its architecture which allows zooming into images to get pixel information and pooling ability. Artificial Neural network (ANN) on the other hand uses weighting and activation functions to perform regression/classification tasks. This study will make use of sequential layers of CNN to perform feature extraction and classification. The study architecture is inspired by a VGG16 architecture and will involve a **feature extraction layers** and **classification layers**. The feature extraction part includes sequences of convolution and pooling layer. Conversely, the classification part includes two layers of feed-forward artificial neural networks (ANN), tasked with classifying images based on features extracted during feature extraction.  The model will be implemented using Keras.\n\n![image.png](attachment:0129c5d2-bc8a-4f5d-999f-41829a5cb39a.png)","metadata":{"_uuid":"81a837ab-8a10-4ab7-800f-03fbbe9aa2de","_cell_guid":"92c3b31e-016a-4ce7-9b8c-6e93452c51b3","trusted":true}},{"cell_type":"markdown","source":"Here is our model, This section is the feature extraction part, each block  contains convolution layers normalization layers and maximum pooling layers.","metadata":{"_uuid":"7eb5559e-f28a-466e-93be-526b6491e3a6","_cell_guid":"1903f20e-7b02-4a3b-8709-b58ae3012c93","trusted":true}},{"cell_type":"code","source":"model=Sequential(name=\"Full_Model\")\n# Block 1\nmodel.add(Input(shape=(image_height,image_width,1),name=\"input\"))\nmodel.add(Conv2D(64, (3, 3), padding='same', activation='relu',name=\"block1_conv_1\"))\nmodel.add(BatchNormalization(name=\"block1_batch_normalization1\"))\nmodel.add(Conv2D(64, (3, 3), padding='same', activation='relu',name=\"block1_conv_2\"))\nmodel.add(BatchNormalization(name=\"block1_batch_normalization2\"))\nmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2),name=\"block1_maxpool\"))\n\n# Block 2\n\nmodel.add(Conv2D(128, (3, 3), padding='same', activation='relu',name=\"block2_conv_1\"))\nmodel.add(BatchNormalization(name=\"block2_batch_normalization1\"))\nmodel.add(Conv2D(128, (3, 3), padding='same', activation='relu',name=\"block2_conv_2\"))\nmodel.add(BatchNormalization(name=\"block2_batch_normalization2\"))\nmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2),name=\"block2_maxpool\"))\n          \n# Block 3\nmodel.add(Conv2D(256, (3, 3), padding='same', activation='relu',name=\"block3_conv_1\"))\nmodel.add(BatchNormalization(name=\"block3_batch_normalization1\"))\nmodel.add(Conv2D(256, (3, 3), padding='same', activation='relu',name=\"block3_conv_2\"))\nmodel.add(BatchNormalization(name=\"block3_batch_normalization2\"))\nmodel.add(Conv2D(256, (3, 3), padding='same', activation='relu',name=\"block3_conv_3\"))\nmodel.add(BatchNormalization(name=\"block3_batch_normalization3\"))\nmodel.add(MaxPooling2D(pool_size=(2, 2),strides=(2,2),name=\"block3_maxpool\"))\n\n# Block 4\nmodel.add(Conv2D(512, (3, 3), padding='same', activation='relu',name=\"block4_conv_1\"))\nmodel.add(BatchNormalization(name=\"block4_batch_normalization1\"))\nmodel.add(Conv2D(512, (3, 3), padding='same', activation='relu',name=\"block4_conv_2\"))\nmodel.add(BatchNormalization(name=\"block4_batch_normalization2\"))\nmodel.add(Conv2D(512, (3, 3), padding='same', activation='relu',name=\"block4_conv_3\"))\nmodel.add(BatchNormalization(name=\"block4_batch_normalization3\"))\nmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2),name=\"block4_maxpool\"))\n\n# fifth convolution layer\n\nmodel.add(Conv2D(512, (3, 3), padding='same', activation='relu',name=\"block5_conv_1\"))\nmodel.add(BatchNormalization(name=\"block5_batch_normalization1\"))\nmodel.add(Conv2D(512, (3, 3), padding='same', activation='relu',name=\"block5_conv_2\"))\nmodel.add(BatchNormalization(name=\"block5_batch_normalization2\"))\nmodel.add(Conv2D(512, (3, 3), padding='same', activation='relu',name=\"block5_conv_3\"))\nmodel.add(BatchNormalization(name=\"block5_batch_normalization3\"))\nmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2),name=\"block5_maxpool\"))\n#  flatten\nmodel.add(Flatten(name=\"flatten_layer\"))","metadata":{"_uuid":"16b74b2b-f220-4c78-b10f-a4f4062002bf","_cell_guid":"6f50f521-a635-4413-845b-935f020ad273","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-11-07T06:22:28.599503Z","iopub.execute_input":"2022-11-07T06:22:28.599978Z","iopub.status.idle":"2022-11-07T06:22:28.950863Z","shell.execute_reply.started":"2022-11-07T06:22:28.599943Z","shell.execute_reply":"2022-11-07T06:22:28.949621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Adding dense layers\n\nHere we will connect the feature extraction part with the ANN classifier to produce a single model like shown on the figure above.","metadata":{"_uuid":"981ef444-287e-4e7e-84f5-f5ac16b97e0a","_cell_guid":"b50e8482-3a95-4dd6-8bcd-90b04376a405","trusted":true}},{"cell_type":"code","source":"# Dense connected layers\nmodel.add(Dense(units=64,activation=\"relu\"))\nmodel.add(Dense(units=64,activation=\"relu\"))\nmodel.add(Dense(units=2, activation=\"softmax\"))","metadata":{"_uuid":"253532ca-bd4d-4a41-9640-1a15a2ec9e18","_cell_guid":"40fd8b65-4050-40d2-b139-b08a15241cda","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-11-07T06:22:28.952572Z","iopub.execute_input":"2022-11-07T06:22:28.952983Z","iopub.status.idle":"2022-11-07T06:22:29.031196Z","shell.execute_reply.started":"2022-11-07T06:22:28.952944Z","shell.execute_reply":"2022-11-07T06:22:29.029396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model.summary()","metadata":{"_uuid":"ac5fdf6a-f697-4b41-aa37-0211ec5e37e0","_cell_guid":"c12a2fdf-42f7-4864-8941-520d73feb2bb","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-11-07T06:22:29.032911Z","iopub.execute_input":"2022-11-07T06:22:29.033594Z","iopub.status.idle":"2022-11-07T06:22:29.038226Z","shell.execute_reply.started":"2022-11-07T06:22:29.033558Z","shell.execute_reply":"2022-11-07T06:22:29.036891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Compile and fit the ANN model. \n\nA sparse categoricalCrossentropy will be used.","metadata":{"_uuid":"a10446b1-8fed-4b70-b776-e055f69c2098","_cell_guid":"f75ffde0-da55-4048-a8f5-6d0ec4c406b9","trusted":true}},{"cell_type":"code","source":"model.compile(\n  optimizer='adam',\n  loss=\"categorical_crossentropy\",\n  metrics=[\"accuracy\",\n           tf.keras.metrics.Recall(name=\"Sensitivity\",class_id=0),\n           tf.keras.metrics.Recall(name=\"Specificity\",class_id=1),\n           tf.keras.metrics.Precision(name=\"Precision\",class_id=0),\n          tfa.metrics.F1Score(num_classes=2, average=\"micro\")])","metadata":{"_uuid":"398d9688-bf21-4acd-a49b-0daacdac2479","_cell_guid":"2baf983f-9ba0-464b-a062-f45a7833ae4a","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-11-07T06:22:29.040081Z","iopub.execute_input":"2022-11-07T06:22:29.040985Z","iopub.status.idle":"2022-11-07T06:22:29.106854Z","shell.execute_reply.started":"2022-11-07T06:22:29.040899Z","shell.execute_reply":"2022-11-07T06:22:29.105663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To make the code we will use the first 20 Batches. But later we will run the code with the full data","metadata":{"_uuid":"87a6b0b2-5cc5-43ad-a98b-74f08b7b07d5","_cell_guid":"f3eccaac-22c6-413b-8417-59bb9288bc5e","trusted":true}},{"cell_type":"code","source":"train_ds=train_ds.take(n)","metadata":{"_uuid":"d8c5c6ab-2520-4125-9c93-4993d2944176","_cell_guid":"eb1b9657-8504-4853-815e-514d8313b507","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-11-07T06:22:29.109299Z","iopub.execute_input":"2022-11-07T06:22:29.109923Z","iopub.status.idle":"2022-11-07T06:22:29.116299Z","shell.execute_reply.started":"2022-11-07T06:22:29.109885Z","shell.execute_reply":"2022-11-07T06:22:29.114550Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# fitting the model","metadata":{"_uuid":"084918f1-cd21-47c2-b197-929e2eeb5a4e","_cell_guid":"91976caa-456e-4004-b035-170cfe498751","trusted":true}},{"cell_type":"code","source":"hist=model.fit(\n train_ds,\n  validation_data=test_ds,\n epochs=epochs)\n","metadata":{"_uuid":"04ec0835-f77d-4989-9e3a-513933b45013","_cell_guid":"d4d8b5f1-1e46-43a7-bc7b-d6847c0db175","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-11-07T06:27:40.997189Z","iopub.execute_input":"2022-11-07T06:27:40.997597Z","iopub.status.idle":"2022-11-07T06:30:38.467252Z","shell.execute_reply.started":"2022-11-07T06:27:40.997563Z","shell.execute_reply":"2022-11-07T06:30:38.465996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n#Accuracy\nfigure,ax=plt.subplots(nrows=1,ncols=2,figsize=(15,6))\nax[0].plot(hist.history['accuracy'])\nax[0].plot(hist.history['val_accuracy'])\nax[0].set_title('model accuracy')\nax[0].set_ylabel('accuracy')\nax[0].set_xlabel('epoch')\nax[0].legend(['train', 'test'], loc='upper left')\n\n# loss\nax[1].plot(hist.history['loss'])\nax[1].plot(hist.history['val_loss'])\nax[1].set_title('model loss')\nax[1].set_ylabel('loss')\nax[1].set_xlabel('epoch')\nax[1].legend(['train', 'test'], loc='upper left')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Graphing accuracy on training vs testing set.","metadata":{"_uuid":"360a9a33-cadb-4375-a454-9152cabd7b53","_cell_guid":"0d534f08-d722-455b-82f7-cd6f68f1719b","trusted":true}},{"cell_type":"code","source":"#Accuracy\nfigure,ax=plt.subplots(nrows=1,ncols=2,figsize=(15,6))\nax[0].plot(hist.history['accuracy'])\nax[0].plot(hist.history['val_accuracy'])\nax[0].set_title('model accuracy')\nax[0].set_ylabel('accuracy')\nax[0].set_xlabel('epoch')\nax[0].legend(['train', 'test'], loc='upper left')\n\n# loss\nax[1].plot(hist.history['loss'])\nax[1].plot(hist.history['val_loss'])\nax[1].set_title('model loss')\nax[1].set_ylabel('loss')\nax[1].set_xlabel('epoch')\nax[1].legend(['train', 'test'], loc='upper left')\nplt.savefig('original data3.png')","metadata":{"_uuid":"b22a78d0-524d-4068-b0ed-126821deb1bf","_cell_guid":"146a2a58-2827-4385-8ea6-b6195bd459c5","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Here is the model perfomance metric.","metadata":{"_uuid":"9e9293ae-6e35-4226-8bd3-5d873247aef2","_cell_guid":"2d040eaa-e577-4244-adaf-3efe8aae5ab8","trusted":true}},{"cell_type":"code","source":"#m1=model.evaluate(test_ds)\nst = time.time()\nm1=model.evaluate(test_ds)[1:6]\net = time.time()\nelapsed_time=round((et - st)/len(testlabs),4)\nprint('Execution time:', elapsed_time, 'seconds')\nm1.append(elapsed_time)\nmod1=pd.DataFrame({\"Measure\":['Accuracy','Sensitivity','Specificty','Precision',\"F1-score\",\"Excecution time\"],\n    \"Original Dataset\":[np.round(float(i), 4) for i in m1]})\nmod1","metadata":{"_uuid":"f9e39648-2678-4860-a892-06d20c5b9766","_cell_guid":"dc7fe9ef-5680-44e5-9fdd-4eb8ac363738","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# save model and data","metadata":{"_uuid":"410a841d-5944-4195-aa2e-2e8798f2be2a","_cell_guid":"086adecf-5ef3-4ec9-b274-32678f2b94d4","trusted":true}},{"cell_type":"code","source":"model.save(\"my_model\")\ntrain_ds.save(\"train_ds\")\ntest_ds.save(\"test_ds\")\n\n\nwith open(\"original_hist.pkl\",\"wb\") as file:\n    pickle.dump(hist,file)\n    \n#with open(\"original_hist.pkl\",\"rb\") as file:\n#    hist=pickle.load(file)\n    \n#model = keras.models.load_model('my_model')\n#train_ds=tf.data.Dataset.load(\"train_ds\")\n#test_ds=tf.data.Dataset.load(\"test_ds\")","metadata":{"_uuid":"de283166-0e51-49b3-a7ba-4fafbd6d3238","_cell_guid":"0fadda6d-f943-4c33-8a05-6479f4b3958f","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-11-07T05:39:46.572091Z","iopub.execute_input":"2022-11-07T05:39:46.572884Z","iopub.status.idle":"2022-11-07T05:39:53.352022Z","shell.execute_reply.started":"2022-11-07T05:39:46.572841Z","shell.execute_reply":"2022-11-07T05:39:53.350469Z"},"trusted":true},"execution_count":null,"outputs":[]}]}